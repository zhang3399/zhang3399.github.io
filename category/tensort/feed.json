{
    "version": "https://jsonfeed.org/version/1",
    "title": "CodeVortex记事本 • All posts by \"tensort\" category",
    "description": "滴答滴答滴答",
    "home_page_url": "https://zhang3399.github.io",
    "items": [
        {
            "id": "https://zhang3399.github.io/2025/05/16/tensoRT/2025-5-16-tensoRT%E5%AE%89%E8%A3%85/",
            "url": "https://zhang3399.github.io/2025/05/16/tensoRT/2025-5-16-tensoRT%E5%AE%89%E8%A3%85/",
            "title": "tensoRT安装",
            "date_published": "2025-05-16T02:00:00.000Z",
            "content_html": "<blockquote>\n<p>tensoRT 是 NVIDIA 推出的一款深度学习推理框架，可以在 GPU 上加速深度学习模型的推理过程。</p>\n</blockquote>\n<h1 id=\"准备工作\"><a class=\"markdownIt-Anchor\" href=\"#准备工作\">#</a> 准备工作</h1>\n<p>安装 tensoRT 需要先安装 CUDA 和 cuDNN。</p>\n<ul>\n<li>CUDA 下载地址：<a href=\"https://developer.nvidia.com/cuda-downloads\">https://developer.nvidia.com/cuda-downloads</a></li>\n<li>cuDNN 下载地址：<a href=\"https://developer.nvidia.com/cudnn\">https://developer.nvidia.com/cudnn</a><br>\n 安装 CUDA 需要注意选择正确的版本，CUDA 版本和 cuDNN 版本需要对应。</li>\n</ul>\n<h1 id=\"tensort安装\"><a class=\"markdownIt-Anchor\" href=\"#tensort安装\">#</a> tensoRT 安装</h1>\n<ol>\n<li>查看 CUDA 版本</li>\n</ol>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>nvcc <span class=\"token parameter variable\">--version</span></pre></td></tr></table></figure><p><img loading=\"lazy\" src=\"/images/nvcc_version.png\" alt=\"\"><br>\n我的是 CUDA 11.1 版本</p>\n<ol start=\"2\">\n<li>\n<p>选择 tensoRT 安装版本<br>\n tensoRT 官方下载地址：<a href=\"https://developer.nvidia.com/tensorrt/download\">https://developer.nvidia.com/tensorrt/download</a><br>\n<img loading=\"lazy\" src=\"/images/tensoRT_version.png\" alt=\"\"><br>\n 选择对应的安装版本，我是选的 <code>8.*</code>  版本， <code>7.*</code>  版本缺少后续官方最新安装教程的 <code>python.wheel</code>  文件</p>\n</li>\n<li>\n<p>下载安装包<br>\n点击同意协议<br>\n<img loading=\"lazy\" src=\"/images/tensoRT_agree.png\" alt=\"\"><br>\n选择对应的版本下载，注意支持的 CUDA 版本<br>\n<img loading=\"lazy\" src=\"/images/seleck_tensoRT_version.png\" alt=\"\"></p>\n</li>\n<li>\n<p>添加 TensoRT 库文件到环境变量</p>\n</li>\n</ol>\n<ul>\n<li>确认下载路径，将文件中的 <code>lib</code>  包文件路径添加到系统环境变量，我的是 <code>D:\\SoftwareDevelopment\\programer\\TensorRT-8.2.2.1\\lib</code> .</li>\n<li>将解压文件的 <code>bin</code> 、 <code>include</code>  目录文件复制粘贴到 <code>CUDA</code>  安装目录下的 <code>lib\\x64</code> 、 <code>include</code>  中，我 <code>CUDA</code>  安装位置在 <code>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1</code> 。</li>\n</ul>\n<ol start=\"5\">\n<li>安装 <code>TensorRT Python wheel</code>  文件<br>\n cd 到下载的安装包路径中的 python 路径下，执行以下命令安装：</li>\n</ol>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>python.exe <span class=\"token parameter variable\">-m</span> pip <span class=\"token function\">install</span> tensorrt-8.2.2.1-cp39-none-win_amd64.whl</pre></td></tr></table></figure><p>（<strong>注意</strong>：cp39 要替换为自己安装 python 解释器的版本，可以终端执行 <code>python -version</code>  查看）</p>\n<p>启动 anaconda 虚拟环境，切换到 python3.9 环境，再次执行执行 <code>python.exe -m pip install tensorrt-8.2.2.1-cp39-none-win_amd64.whl</code> ：<br>\n<img loading=\"lazy\" src=\"/images/tensoRT_python_ok.png\" alt=\"\"><br>\n6. 检验<br>\n正常安装完成后，执行以下命令检验，如果输出 <code>8.2.2.1</code>  类似版本，则表示安装成功。</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">import</span> tensort</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>print<span class=\"token punctuation\">(</span>tensort.__version__<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>如果提示错误：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>FileNotFoundError: Could not find: nvinfer_10.dll. Is it on your <span class=\"token environment constant\">PATH</span>?</pre></td></tr></table></figure><p>将 tensort 解压文件夹中 <code>lib</code>  目录中的 <code>dll</code>  后缀文件复制到 <code>bin</code>  目录中，重新执行 <code>import tensort</code>  即可。</p>\n<ol start=\"7\">\n<li>测试案例<br>\n官方 python 构建示例：<a href=\"https://docs.nvidia.com/deeplearning/tensorrt/latest/inference-library/python-api-docs.html\">https://docs.nvidia.com/deeplearning/tensorrt/latest/inference-library/python-api-docs.html</a></li>\n</ol>\n<p>下载 <code>resnet18</code>  模型，将 pytorch 模型的 <code>.pt</code>  文件转为 <code>.onnx</code>  文件：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> torch</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> torchvision<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">as</span> models</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> onnx</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> onnxruntime</pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># 加载 PyTorch 模型</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>model <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>resnet18<span class=\"token punctuation\">(</span>weights<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># 定义输入和输出张量的名称和形状</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>input_names <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"input\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>output_names <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"output\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>batch_size <span class=\"token operator\">=</span> <span class=\"token number\">1</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>input_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">224</span><span class=\"token punctuation\">,</span> <span class=\"token number\">224</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>output_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token comment\"># 将 PyTorch 模型转换为 ONNX 格式</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>torch<span class=\"token punctuation\">.</span>onnx<span class=\"token punctuation\">.</span>export<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    model<span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 要转换的 PyTorch 模型</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span>input_shape<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 模型输入的随机张量</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    <span class=\"token string\">\"resnet18.onnx\"</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 保存的 ONNX 模型的文件名</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    input_names<span class=\"token operator\">=</span>input_names<span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 输入张量的名称</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    output_names<span class=\"token operator\">=</span>output_names<span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 输出张量的名称</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    dynamic_axes<span class=\"token operator\">=</span><span class=\"token punctuation\">&#123;</span>input_names<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">&#123;</span><span class=\"token number\">0</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"batch_size\"</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span> output_names<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">&#123;</span><span class=\"token number\">0</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"batch_size\"</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span>  <span class=\"token comment\"># 动态轴，即输入和输出张量可以具有不同的批次大小</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token comment\"># 加载 ONNX 模型</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>onnx_model <span class=\"token operator\">=</span> onnx<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">\"resnet18.onnx\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>onnx_model_graph <span class=\"token operator\">=</span> onnx_model<span class=\"token punctuation\">.</span>graph</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>onnx_session <span class=\"token operator\">=</span> onnxruntime<span class=\"token punctuation\">.</span>InferenceSession<span class=\"token punctuation\">(</span>onnx_model<span class=\"token punctuation\">.</span>SerializeToString<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre></pre></td></tr><tr><td data-num=\"32\"></td><td><pre><span class=\"token comment\"># 使用随机张量测试 ONNX 模型</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span>input_shape<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>onnx_output <span class=\"token operator\">=</span> onnx_session<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>output_names<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">&#123;</span>input_names<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre></pre></td></tr><tr><td data-num=\"36\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"PyTorch output: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>model<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>from_numpy<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>detach<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token format-spec\">5]</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"ONNX output: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>onnx_output<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token format-spec\">5]</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p><strong>tensoRT 构建引擎：</strong><br>\n<strong>方式 1</strong>：<br>\n使用 <code>trtexec</code>  工具</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>trtexec <span class=\"token parameter variable\">--onnx</span><span class=\"token operator\">=</span>resnet18.onnx <span class=\"token parameter variable\">--saveEngine</span><span class=\"token operator\">=</span>resnet18.engine <span class=\"token parameter variable\">--float16</span></pre></td></tr></table></figure><p><strong>方式 2：</strong><br>\n使用 <code>python</code>  脚本</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> tensorrt <span class=\"token keyword\">as</span> trt</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 加载 ONNX 模型</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>onnx_file_path <span class=\"token operator\">=</span> <span class=\"token string\">\"resnet18.onnx\"</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>onnx_model <span class=\"token operator\">=</span> trt<span class=\"token punctuation\">.</span>OnnxParser<span class=\"token punctuation\">.</span>create_network<span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    parser<span class=\"token operator\">=</span>trt<span class=\"token punctuation\">.</span>OnnxParser<span class=\"token punctuation\">(</span>network<span class=\"token operator\">=</span>trt<span class=\"token punctuation\">.</span>Network<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># 创建一个 ONNX 解析器</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    flags<span class=\"token operator\">=</span><span class=\"token number\">0</span>  <span class=\"token comment\"># 解析器标志，0 表示默认值</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>onnx_file_path<span class=\"token punctuation\">,</span> <span class=\"token string\">\"rb\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> model_file<span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 打开 ONNX 模型文件</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    onnx_model<span class=\"token punctuation\">.</span>deserialize<span class=\"token punctuation\">(</span>model_file<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 反序列化 ONNX 模型</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\"># 创建 TensorRT 引擎</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>trt_logger <span class=\"token operator\">=</span> trt<span class=\"token punctuation\">.</span>Logger<span class=\"token punctuation\">(</span>trt<span class=\"token punctuation\">.</span>Logger<span class=\"token punctuation\">.</span>WARNING<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 创建一个 TensorRT 日志记录器</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>trt_builder <span class=\"token operator\">=</span> trt<span class=\"token punctuation\">.</span>Builder<span class=\"token punctuation\">(</span>trt_logger<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 创建一个 TensorRT 构建器</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>trt_builder<span class=\"token punctuation\">.</span>max_batch_size <span class=\"token operator\">=</span> <span class=\"token number\">1</span>  <span class=\"token comment\"># 设置最大批次大小</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>trt_builder<span class=\"token punctuation\">.</span>max_workspace_size <span class=\"token operator\">=</span> <span class=\"token number\">1</span> <span class=\"token operator\">&lt;&lt;</span> <span class=\"token number\">30</span>  <span class=\"token comment\"># 设置最大工作空间大小</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>trt_builder<span class=\"token punctuation\">.</span>fp16_mode <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>  <span class=\"token comment\"># 启用 FP16 模式</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>trt_builder<span class=\"token punctuation\">.</span>int8_mode <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>  <span class=\"token comment\"># 禁用 INT8 模式</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>trt_engine <span class=\"token operator\">=</span> trt_builder<span class=\"token punctuation\">.</span>build_cuda_engine<span class=\"token punctuation\">(</span>onnx_model<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 构建 TensorRT 引擎</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre></pre></td></tr><tr><td data-num=\"22\"></td><td><pre><span class=\"token comment\"># 保存 TensorRT 引擎</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>trt_engine_path <span class=\"token operator\">=</span> <span class=\"token string\">\"resnet18.engine\"</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>trt_engine<span class=\"token punctuation\">.</span>serialize<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>tofile<span class=\"token punctuation\">(</span>trt_engine_path<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 将 TensorRT 引擎序列化为字节流并保存到文件中</span></pre></td></tr></table></figure><p>使用 <code>tensoRT</code>  模型进行推理：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> tensorrt <span class=\"token keyword\">as</span> trt</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> pycuda<span class=\"token punctuation\">.</span>driver <span class=\"token keyword\">as</span> cuda</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> pycuda<span class=\"token punctuation\">.</span>autoinit</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np</pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># 加载 TensorRT 引擎</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>trt_engine_path <span class=\"token operator\">=</span> <span class=\"token string\">\"resnet18.trt\"</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>trt_engine <span class=\"token operator\">=</span> trt<span class=\"token punctuation\">.</span>Runtime<span class=\"token punctuation\">(</span>trt<span class=\"token punctuation\">.</span>Logger<span class=\"token punctuation\">(</span>trt<span class=\"token punctuation\">.</span>Logger<span class=\"token punctuation\">.</span>WARNING<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>deserialize_cuda_engine<span class=\"token punctuation\">(</span>trt_engine_path<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># 创建执行上下文</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>trt_context <span class=\"token operator\">=</span> trt_engine<span class=\"token punctuation\">.</span>create_execution_context<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\"># 定义输入和输出张量的形状</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>input_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">224</span><span class=\"token punctuation\">,</span> <span class=\"token number\">224</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>output_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token comment\"># 分配内存</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>input_memory <span class=\"token operator\">=</span> cuda<span class=\"token punctuation\">.</span>mem_alloc<span class=\"token punctuation\">(</span>trt_engine<span class=\"token punctuation\">.</span>get_binding_shape<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> trt<span class=\"token punctuation\">.</span>volume<span class=\"token punctuation\">(</span>input_shape<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>output_memory <span class=\"token operator\">=</span> cuda<span class=\"token punctuation\">.</span>mem_alloc<span class=\"token punctuation\">(</span>trt_engine<span class=\"token punctuation\">.</span>get_binding_shape<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> trt<span class=\"token punctuation\">.</span>volume<span class=\"token punctuation\">(</span>output_shape<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre><span class=\"token comment\"># 准备输入数据</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>input_data <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>input_shape<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre></pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token comment\"># 将输入数据复制到 GPU 内存中</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>cuda<span class=\"token punctuation\">.</span>memcpy_htod<span class=\"token punctuation\">(</span>input_memory<span class=\"token punctuation\">,</span> input_data<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token comment\"># 执行推理</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>trt_context<span class=\"token punctuation\">.</span>execute_v2<span class=\"token punctuation\">(</span>bindings<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>input_memory<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>output_memory<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre></pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token comment\"># 将输出数据从 GPU 内存中复制到主机内存中</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>output_data <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>empty<span class=\"token punctuation\">(</span>output_shape<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>cuda<span class=\"token punctuation\">.</span>memcpy_dtoh<span class=\"token punctuation\">(</span>output_data<span class=\"token punctuation\">,</span> output_memory<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre></pre></td></tr><tr><td data-num=\"34\"></td><td><pre><span class=\"token comment\"># 打印输出结果</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>output_data<span class=\"token punctuation\">)</span></pre></td></tr></table></figure>",
            "tags": [
                "tensoRT"
            ]
        }
    ]
}